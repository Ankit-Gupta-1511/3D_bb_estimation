{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025b4138",
   "metadata": {
    "id": "025b4138"
   },
   "source": [
    "**lib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "QRtb_1EdwckE",
   "metadata": {
    "id": "QRtb_1EdwckE"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ORmhPlWODtTO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORmhPlWODtTO",
    "outputId": "de33aef8-53a5-4680-b983-482117d9fb7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c059fdb",
   "metadata": {
    "id": "0c059fdb"
   },
   "outputs": [],
   "source": [
    "def parse_tf_example(tf_example):\n",
    "    parsed_example = tf.io.parse_single_example(tf_example,\n",
    "                                               {\n",
    "                                                   'image': tf.io.FixedLenFeature((), tf.string),\n",
    "                                                   'dimension': tf.io.VarLenFeature(tf.float32),\n",
    "                                                   'orientation': tf.io.VarLenFeature(tf.float32),\n",
    "                                                   'confidence': tf.io.VarLenFeature(tf.float32)\n",
    "                                               })\n",
    "    return {\"image\": parsed_example['image'],\n",
    "            'dimension': parsed_example['dimension'],\n",
    "            'orientation': parsed_example['orientation'],\n",
    "            'confidence': parsed_example['confidence']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14337bc2",
   "metadata": {
    "id": "14337bc2"
   },
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "542089d8",
   "metadata": {
    "id": "542089d8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import keras.backend as K\n",
    "from keras.utils import plot_model\n",
    "\n",
    "train_file = \"path_to_train_file/train.tfrecords\"\n",
    "number_bin = 2\n",
    "batch_size = 8\n",
    "shuffle_buffer_size = 1000\n",
    "\n",
    "def preprocess(image_dataset):\n",
    "    # parse image\n",
    "    image = tf.io.decode_image(image_dataset[\"image\"])\n",
    "    image = tf.divide(image, 255)\n",
    "    # parse dimension\n",
    "    dimension = image_dataset[\"dimension\"].values\n",
    "    # parse and reshape orientation\n",
    "    orientation = image_dataset[\"orientation\"].values\n",
    "    orientation = tf.reshape(orientation, (number_bin, 2))\n",
    "    # parse confidence\n",
    "    confidence = image_dataset[\"confidence\"].values\n",
    "    return image, (dimension, orientation, confidence)\n",
    "\n",
    "def generate_dataset(file_path):\n",
    "    dataset = tf.data.TFRecordDataset(file_path)\n",
    "    dataset = dataset.map(parse_tf_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    #dataset = dataset.shuffle(shuffle_buffer_size, seed=12)\n",
    "    # split to train and val\n",
    "    dataset_size = 11195\n",
    "    train_size = int(dataset_size*0.8)\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    val_dataset = dataset.skip(train_size)\n",
    "    # create batch\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "train_dataset, val_dataset = generate_dataset(train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec6d90",
   "metadata": {
    "id": "a1ec6d90"
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cde2751",
   "metadata": {
    "id": "4cde2751"
   },
   "outputs": [],
   "source": [
    "def orientation_loss(y_true, y_pred):\n",
    "    # Find number of anchors\n",
    "    anchors = tf.reduce_sum(tf.square(y_true), axis=2)\n",
    "    anchors = tf.greater(anchors, tf.constant(0.5))\n",
    "    anchors = tf.reduce_sum(tf.cast(anchors, tf.float32), 1)\n",
    "\n",
    "    # Define the loss\n",
    "    loss = -(y_true[:,:,0]*y_pred[:,:,0] + y_true[:,:,1]*y_pred[:,:,1])\n",
    "    loss = tf.reduce_sum(loss, axis=1)\n",
    "    loss = loss / anchors\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def build_model():\n",
    "    base_model = VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "    #for layer in base_model.layers:\n",
    "    #    layer.trainable=False\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    # dimesion head\n",
    "    dimension = tf.keras.layers.Dense(512)(x)\n",
    "    dimension = tf.keras.layers.LeakyReLU(alpha=0.1)(dimension)\n",
    "    dimension = tf.keras.layers.Dropout(0.5)(dimension)\n",
    "    dimension = tf.keras.layers.Dense(3)(dimension)\n",
    "    dimension = tf.keras.layers.LeakyReLU(alpha=0.1, name='dimension')(dimension)\n",
    "\n",
    "    # orientation head\n",
    "    orientation = tf.keras.layers.Dense(256)(x)\n",
    "    orientation = tf.keras.layers.LeakyReLU(alpha=0.1)(orientation)\n",
    "    orientation = tf.keras.layers.Dropout(0.5)(orientation)\n",
    "    orientation = tf.keras.layers.Dense(number_bin*2)(orientation)\n",
    "    orientation = tf.keras.layers.LeakyReLU(alpha=0.1)(orientation)\n",
    "    orientation = tf.keras.layers.Reshape((number_bin,-1))(orientation)\n",
    "    orientation = tf.keras.layers.Lambda(K.l2_normalize, name='orientation')(orientation)\n",
    "\n",
    "    # confidence head\n",
    "    confidence = tf.keras.layers.Dense(256)(x)\n",
    "    confidence = tf.keras.layers.LeakyReLU(alpha=0.1)(confidence)\n",
    "    confidence = tf.keras.layers.Dropout(0.5)(confidence)\n",
    "    confidence = tf.keras.layers.Dense(number_bin, activation='softmax', name='confidence')(confidence)\n",
    "    # model\n",
    "    model = tf.keras.models.Model(inputs=base_model.inputs, outputs=[dimension, orientation, confidence])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59375aba",
   "metadata": {
    "id": "59375aba"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5656ce4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5656ce4d",
    "outputId": "f1f7b648-6160-4461-ebc4-cb9491a6fc6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1120/1120 [==============================] - 209s 185ms/step - loss: 0.4539 - dimension_loss: 0.1066 - orientation_loss: -0.2296 - confidence_loss: 0.5769 - val_loss: 0.1845 - val_dimension_loss: 0.0861 - val_orientation_loss: -0.2575 - val_confidence_loss: 0.3559\n",
      "Epoch 2/10\n",
      "1120/1120 [==============================] - 218s 195ms/step - loss: 0.1136 - dimension_loss: 0.1015 - orientation_loss: -0.2680 - confidence_loss: 0.2801 - val_loss: -0.0747 - val_dimension_loss: 0.0810 - val_orientation_loss: -0.3089 - val_confidence_loss: 0.1532\n",
      "Epoch 3/10\n",
      "1120/1120 [==============================] - 205s 183ms/step - loss: -0.0449 - dimension_loss: 0.0917 - orientation_loss: -0.2998 - confidence_loss: 0.1633 - val_loss: -0.1448 - val_dimension_loss: 0.0751 - val_orientation_loss: -0.3215 - val_confidence_loss: 0.1016\n",
      "Epoch 4/10\n",
      "1120/1120 [==============================] - 207s 185ms/step - loss: -0.1123 - dimension_loss: 0.0831 - orientation_loss: -0.3114 - confidence_loss: 0.1161 - val_loss: -0.1828 - val_dimension_loss: 0.0676 - val_orientation_loss: -0.3273 - val_confidence_loss: 0.0769\n",
      "Epoch 5/10\n",
      "1120/1120 [==============================] - 207s 185ms/step - loss: -0.1497 - dimension_loss: 0.0772 - orientation_loss: -0.3168 - confidence_loss: 0.0900 - val_loss: -0.1981 - val_dimension_loss: 0.0649 - val_orientation_loss: -0.3289 - val_confidence_loss: 0.0659\n",
      "Epoch 6/10\n",
      "1120/1120 [==============================] - 208s 185ms/step - loss: -0.1695 - dimension_loss: 0.0738 - orientation_loss: -0.3198 - confidence_loss: 0.0765 - val_loss: -0.2131 - val_dimension_loss: 0.0643 - val_orientation_loss: -0.3307 - val_confidence_loss: 0.0533\n",
      "Epoch 7/10\n",
      "1120/1120 [==============================] - 207s 185ms/step - loss: -0.1869 - dimension_loss: 0.0726 - orientation_loss: -0.3218 - confidence_loss: 0.0622 - val_loss: -0.2278 - val_dimension_loss: 0.0585 - val_orientation_loss: -0.3319 - val_confidence_loss: 0.0456\n",
      "Epoch 8/10\n",
      "1120/1120 [==============================] - 207s 185ms/step - loss: -0.2006 - dimension_loss: 0.0696 - orientation_loss: -0.3237 - confidence_loss: 0.0535 - val_loss: -0.2321 - val_dimension_loss: 0.0577 - val_orientation_loss: -0.3323 - val_confidence_loss: 0.0426\n",
      "Epoch 9/10\n",
      "1120/1120 [==============================] - 210s 187ms/step - loss: -0.2097 - dimension_loss: 0.0680 - orientation_loss: -0.3246 - confidence_loss: 0.0470 - val_loss: -0.2414 - val_dimension_loss: 0.0560 - val_orientation_loss: -0.3335 - val_confidence_loss: 0.0361\n",
      "Epoch 10/10\n",
      "1120/1120 [==============================] - 205s 183ms/step - loss: -0.2169 - dimension_loss: 0.0664 - orientation_loss: -0.3255 - confidence_loss: 0.0423 - val_loss: -0.2422 - val_dimension_loss: 0.0555 - val_orientation_loss: -0.3336 - val_confidence_loss: 0.0359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1119776b90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "# compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss={'dimension': 'mean_squared_error', 'orientation': orientation_loss,\n",
    "                    'confidence': 'binary_crossentropy'},\n",
    "              loss_weights={'dimension': 1., 'orientation': 1., 'confidence': 1.})\n",
    "# define callbacks\n",
    "checkpoint  = tf.keras.callbacks.ModelCheckpoint('/content/weights.hdf5', save_best_only=True, save_weights_only=True)\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='/content/logs/', histogram_freq=0,\n",
    "                                             write_graph=True, write_images=False)\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=10, callbacks=[checkpoint, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JR1f9lk93vJp",
   "metadata": {
    "id": "JR1f9lk93vJp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
