{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b92f27",
   "metadata": {},
   "source": [
    "**lib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "271871ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def draw_boundingbox(image_object, train_image_path):\n",
    "    image_path = os.path.join(train_image_path, image_object[\"image_file_name\"])\n",
    "    image = plt.imread(image_path)\n",
    "    # draw bb\n",
    "    x1 = int(image_object[\"xmin\"])\n",
    "    y1 = int(image_object[\"ymin\"])\n",
    "    x2 = int(image_object[\"xmax\"])\n",
    "    y2 = int(image_object[\"ymax\"])\n",
    "    image = cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(image)\n",
    "\n",
    "def get_bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def get_float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def get_int_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da4cfe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "label_path = '/Users/privy/Desktop/all_repos/3D_bb_estimation/data/label_2'\n",
    "label_name = 'Car'\n",
    "train_image_path = '/Users/privy/Desktop/all_repos/3D_bb_estimation/data/training/image_2'\n",
    "out_file = \"/Users/privy/Desktop/all_repos/3D_bb_estimation/data/train.tfrecords\"\n",
    "number_bin = 2\n",
    "overlap = 0.1\n",
    "image_size = (224, 224)\n",
    "\n",
    "def parse_label(label_path, label_name, train_image_path):\n",
    "    all_objects = []\n",
    "    # we have one label file for each image\n",
    "    for file in os.listdir(label_path):\n",
    "        with open(os.path.join(label_path, file), 'r') as txt_file:\n",
    "            for line in txt_file:\n",
    "                data_list = line.strip().split(\" \")\n",
    "                # considering cars only and which are not truncated and not occluded\n",
    "                label = data_list[0]\n",
    "                truncated = np.abs(float(data_list[1]))\n",
    "                occluded = np.abs(float(data_list[2]))\n",
    "                if label == label_name and truncated < 0.1 and occluded < 0.1:\n",
    "                    # define angle\n",
    "                    angle = float(data_list[3]) + np.pi/2.\n",
    "                    if angle < 0:\n",
    "                        angle = angle + 2.*np.pi\n",
    "                    angle = angle - int(angle/(2.*np.pi))*(2.*np.pi)\n",
    "                    \n",
    "                    car_object = {\n",
    "                        \"image_file_name\": file.replace(\".txt\",\".png\"),\n",
    "                        \"xmin\": float(data_list[4]),\n",
    "                        \"ymin\": float(data_list[5]),\n",
    "                        \"xmax\": float(data_list[6]),\n",
    "                        \"ymax\": float(data_list[7]),\n",
    "                        \"dims\": np.array([float(number) for number in data_list[8:11]]),\n",
    "                        \"angle\": angle,\n",
    "                    }\n",
    "                    all_objects.append(car_object)\n",
    "    return all_objects\n",
    "\n",
    "def compute_anchors(angle, number_bin, overlap):\n",
    "    anchors = []\n",
    "    \n",
    "    wedge = 2.*np.pi/number_bin\n",
    "    l_index = int(angle/wedge)\n",
    "    r_index = l_index + 1\n",
    "    \n",
    "    if (angle - l_index*wedge) < wedge/2 * (1+overlap/2):\n",
    "        anchors.append([l_index, angle - l_index*wedge])\n",
    "        \n",
    "    if (r_index*wedge - angle) < wedge/2 * (1+overlap/2):\n",
    "        anchors.append([r_index%number_bin, angle - r_index*wedge])\n",
    "        \n",
    "    return anchors\n",
    "\n",
    "def write_tfrecords(image, dimension, orientation, confidence, writer):\n",
    "    feature_dict = {\n",
    "        \"image\": get_bytes_feature([image]),\n",
    "        \"dimension\": get_float_feature(dimension),\n",
    "        \"orientation\": get_float_feature(list(orientation)),\n",
    "        \"confidence\": get_float_feature(confidence),\n",
    "    }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "    writer.write(example.SerializeToString())\n",
    "    \n",
    "def main():\n",
    "    # parse label\n",
    "    all_objects = parse_label(label_path, label_name, train_image_path)\n",
    "    # calculate average dimension of car\n",
    "    average_dims = np.mean([obj[\"dims\"] for obj in all_objects], axis=0)\n",
    "    # define tfrecords writer\n",
    "    writer = tf.io.TFRecordWriter(out_file)\n",
    "    for i, image_obj in enumerate(all_objects):\n",
    "        # network need to predict residual value of dimesion\n",
    "        object_dimension = image_obj[\"dims\"] - average_dims\n",
    "    \n",
    "        # network need to predict confidence for number of bin\n",
    "        # if BIN = 2 confidence for bin1 and bin2\n",
    "        confidence = np.zeros(number_bin)\n",
    "    \n",
    "        # network need to predict cos and sin for each bin\n",
    "        orientation = np.zeros((number_bin,2))\n",
    "    \n",
    "        # get anchors\n",
    "        anchors = compute_anchors(image_obj[\"angle\"], number_bin, overlap)\n",
    "        # prepare data for confidence and orientation\n",
    "        for anchor in anchors:\n",
    "            confidence[anchor[0]] = 1\n",
    "            orientation[anchor[0]] = np.array([np.cos(anchor[1]), np.sin(anchor[1])])\n",
    "    \n",
    "        # prepare X\n",
    "        # read and crop image using 2D detection\n",
    "        image_array = cv2.imread(os.path.join(train_image_path, image_obj[\"image_file_name\"]))\n",
    "        cropped_image = image_array[int(image_obj[\"ymin\"]):int(image_obj[\"ymax\"]),\n",
    "                               int(image_obj[\"xmin\"]):int(image_obj[\"xmax\"])]\n",
    "        cropped_image = cv2.resize(cropped_image, image_size)\n",
    "        _, encoded_image = cv2.imencode('.png', cropped_image)\n",
    "        encoded_image = encoded_image.tobytes()\n",
    "    \n",
    "        # write data to tfrecords\n",
    "        # resize orientation to number_bin*2, 1\n",
    "        orientation = np.resize(orientation, (number_bin*2))\n",
    "        write_tfrecords(encoded_image, object_dimension, orientation, confidence, writer)\n",
    "        if i == 200:\n",
    "            break\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226b160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
